{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2_QuickStart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2/szV67Iq9dY7YcVFG4Af",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/squeeko/TensorflowProjects/blob/master/Tensorflow2_QuickStart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njNTx2tkCxpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HFVmbwnFxQE",
        "colab_type": "text"
      },
      "source": [
        "Load and prepare the MNIST dataset. Convert the samples from integers to floating-point numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHFoIBEgDtMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fbf97e2a-2718-4e7e-c7d8-2e9a26e59a8a"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-sl1M7sF0yY",
        "colab_type": "text"
      },
      "source": [
        "Build the tf.keras.Sequential model by stacking layers. Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO9veAU2ECwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "                                    tf.keras.layers.Dense(128, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arcd3Vh6F7Kq",
        "colab_type": "text"
      },
      "source": [
        "For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRMkOyXiEnY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e3e4793e-e13c-49fb-f72c-c0b84e9fb70a"
      },
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.58306307, -0.70052946, -0.02297604,  0.5340719 ,  0.06329438,\n",
              "        -0.24514839,  0.70404416,  0.05417342,  0.26297706, -0.33305806]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKzrmmYFF-2y",
        "colab_type": "text"
      },
      "source": [
        "The tf.nn.softmax function converts these logits to \"probabilities\" for each class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWxfzO7dFUvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "068a3bd8-40de-419b-c799-0a8e618d04e1"
      },
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05226121, 0.04646912, 0.09150022, 0.15971474, 0.09974449,\n",
              "        0.07327131, 0.18930541, 0.09883887, 0.12178954, 0.06710505]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR0ps-9AHyXl",
        "colab_type": "text"
      },
      "source": [
        "**Note:** It is possible to bake this tf.nn.softmax in as the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwzaoe-BH5hj",
        "colab_type": "text"
      },
      "source": [
        "The ***losses.SparseCategoricalCrossentropy*** loss takes a vector of logits and a True index and returns a scalar loss for each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4xIURiCHs91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df3IXuBKIS7p",
        "colab_type": "text"
      },
      "source": [
        "This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.log(1/10) ~= 2.6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DohIUR0gIMme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e416ad0-5be1-4d07-d2c3-248ced658926"
      },
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6135862"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zjQ83CKInqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArX0AoiWJGQy",
        "colab_type": "text"
      },
      "source": [
        "The Model.fit method adjusts the model parameters to minimize the loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nZzy-ujJDI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d938fa7-1332-4e63-c9b4-565f6f113455"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.9158\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1441 - accuracy: 0.9568\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1079 - accuracy: 0.9673\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0882 - accuracy: 0.9727\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0739 - accuracy: 0.9766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f85c277ecf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHhfR1O4JY_6",
        "colab_type": "text"
      },
      "source": [
        "The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1BaVgoMJQ5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2ab83a1-f5d1-43bb-82da-156ce86374e3"
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.0770 - accuracy: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07695811241865158, 0.9775000214576721]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7BOehtVJsn1",
        "colab_type": "text"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFWBlIKSJw-I",
        "colab_type": "text"
      },
      "source": [
        "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qu3CkpOJkjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "                                         model,\n",
        "                                         tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAH7EgP9J_3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d9868ab9-5158-4252-8ae6-2e2fb7841909"
      },
      "source": [
        "probability_model(x_test[:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[2.6364760e-06, 7.7265003e-09, 1.4079367e-05, 1.4339946e-04,\n",
              "        2.8003952e-11, 4.2901490e-08, 2.5099730e-13, 9.9983788e-01,\n",
              "        4.6927596e-07, 1.5126269e-06],\n",
              "       [1.2419268e-10, 1.0290239e-05, 9.9998856e-01, 1.0004338e-06,\n",
              "        1.5415449e-15, 7.9716711e-10, 4.1797494e-09, 4.7296412e-13,\n",
              "        9.8904017e-08, 2.8735324e-15],\n",
              "       [2.7101951e-08, 9.9882585e-01, 4.1217598e-05, 6.0600161e-07,\n",
              "        1.7146227e-06, 9.4931335e-07, 6.6033272e-07, 1.0399391e-03,\n",
              "        8.8962115e-05, 8.8257131e-08],\n",
              "       [9.9989319e-01, 2.7078645e-08, 3.7031172e-05, 3.1814618e-06,\n",
              "        1.6029771e-06, 3.5413013e-05, 2.3772884e-05, 2.2389825e-06,\n",
              "        4.3156238e-08, 3.5396554e-06],\n",
              "       [5.8534733e-06, 2.8482774e-10, 2.1669330e-05, 5.2961667e-08,\n",
              "        9.9952602e-01, 5.5673024e-07, 1.3114072e-06, 4.4961876e-06,\n",
              "        2.7019760e-07, 4.3973941e-04]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}